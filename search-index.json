import fs from "fs-extra";
import path from "path";
import removeDiacritics from "remove-diacritics";

const DOCS_DIR = "./docs";
const OUTPUT = "./public/search-index.json";

const STRONGS_RE = /\b([HG])0*(\d{1,4})\b/gi;
const REF_RE = /\b([1-3]?\s?[A-Z][a-z]+)\s+(\d+):(\d+)\b/g;

/* ---------- Normalizers ---------- */

function normalizeHebrew(text) {
  return text
    .replace(/[\u0591-\u05C7]/g, "") // niqqud + cantillation
    .replace(/[ך]/g, "כ")
    .replace(/[ם]/g, "מ")
    .replace(/[ן]/g, "נ")
    .replace(/[ף]/g, "פ")
    .replace(/[ץ]/g, "צ");
}

function normalizeGreek(text) {
  return removeDiacritics(text).toLowerCase();
}

function normalizeEnglish(text) {
  return text.toLowerCase();
}

function normalizeText(text) {
  return normalizeEnglish(
    normalizeGreek(
      normalizeHebrew(text)
    )
  );
}

/* ---------- Strong’s Extraction ---------- */

function extractStrongs(text) {
  const results = new Set();
  let match;
  while ((match = STRONGS_RE.exec(text)) !== null) {
    const prefix = match[1].toUpperCase();
    const num = match[2].padStart(4, "0");
    results.add(`${prefix}${num}`);
    results.add(num);
  }
  return [...results];
}

/* ---------- Main Index Builder ---------- */

async function buildIndex() {
  const files = await fs.readdir(DOCS_DIR);
  const index = [];

  for (const file of files) {
    if (!file.endsWith(".md") && !file.endsWith(".txt")) continue;

    const docId = path.basename(file, path.extname(file));
    const content = await fs.readFile(path.join(DOCS_DIR, file), "utf8");

    let offset = 0;
    const lines = content.split(/\n+/);

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i].trim();
      if (!line) {
        offset += lines[i].length + 1;
        continue;
      }

      const strongs = extractStrongs(line);
      const refs = [...line.matchAll(REF_RE)];

      const ref = refs.length
        ? `${refs[0][1]} ${refs[0][2]}:${refs[0][3]}`
        : "";

      index.push({
        id: `${docId}_${i}`,
        docId,
        docTitle: file,
        section: ref.split(":")[0] || "",
        ref,
        position: offset,
        text: line,
        text_norm: normalizeText(line),
        languageTags: detectLanguage(line),
        strongs
      });

      offset += lines[i].length + 1;
    }
  }

  await fs.ensureDir(path.dirname(OUTPUT));
  await fs.writeJson(OUTPUT, index, { spaces: 2 });

  console.log(`Indexed ${index.length} records`);
}

/* ---------- Language Detection (lightweight) ---------- */

function detectLanguage(text) {
  const tags = [];
  if (/[א-ת]/.test(text)) tags.push("he");
  if (/[α-ωΑ-Ω]/.test(text)) tags.push("el");
  if (/[a-zA-Z]/.test(text)) tags.push("en");
  return tags;
}

buildIndex().catch(console.error);
